{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "\n",
    "import itertools as it\n",
    "from functools import reduce\n",
    "import treecorr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['savefig.dpi'] = 120\n",
    "matplotlib.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "#cluster = LocalCluster(n_workers=8, \n",
    "#                       threads_per_worker=1,\n",
    "#                       memory_limit='6Gb')\n",
    "#client = Client(cluster)\n",
    "\n",
    "dask.config.config[\"distributed\"][\"dashboard\"][\"link\"] = \"{JUPYTERHUB_SERVICE_PREFIX}proxy/{host}:{port}/status\"\n",
    "client = Client(scheduler_file='/global/cscratch1/sd/cwalter/scheduler.json')\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "\n",
    "scratch= os.environ[\"SCRATCH\"]\n",
    "\n",
    "file_path = '/global/cscratch1/sd/cwalter/parquet-with-healpixels/'\n",
    "selected = ['galaxy_id', 'mag_i', 'redshift_true', 'ra', 'dec', 'shear_1', 'shear_2']\n",
    "rename_map = {'galaxy_id':'id', 'redshift_true':'z', 'shear_1':'g1', 'shear_2':'g2'}\n",
    "\n",
    "df = dd.read_parquet(file_path+'skysim-*.parquet', columns=selected)\n",
    "df = df.rename(columns=rename_map)\n",
    "#df = df.sample(frac=.000001)\n",
    "df = df.sample(frac=.1)\n",
    "\n",
    "#selected = ['id', 'mag_r', 'z', 'ra', 'dec', 'g1', 'g2']\n",
    "#df = dd.read_parquet(f'{scratch}/parquet-skysim/*.parquet', columns=selected, engine='pyarrow')\n",
    "\n",
    "#df = df.persist()\n",
    "\n",
    "number_in_df = df.index.size.compute()\n",
    "print('Columns:', df.columns.values, '#Rows:', number_in_df/1e9)\n",
    "print(f'There are {number_in_df:,d} elements in the area with {comb(number_in_df, 2, exact=True):,d} total combinations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from healpy.pixelfunc import ang2pix\n",
    "from healpy.pixelfunc import pix2ang\n",
    "from healpy.rotator import angdist\n",
    "\n",
    "NSIDE = 32\n",
    "\n",
    "def add_healpixels(dataframe):\n",
    "    return ang2pix(NSIDE, dataframe.ra.to_numpy(), dataframe.dec.to_numpy(), lonlat=True)\n",
    "\n",
    "def angular_distance(pairs):\n",
    "    \n",
    "    pixel1 = pix2ang(NSIDE, pairs[:,0])\n",
    "    pixel2 = pix2ang(NSIDE, pairs[:,1])\n",
    "    \n",
    "    seperation = angdist(pixel1, pixel2)*180/np.pi*60 # in arcmin\n",
    "    \n",
    "    return seperation\n",
    "\n",
    "@delayed\n",
    "def cross(dataframe1, dataframe2, pixel1, pixel2):\n",
    "    \n",
    "    gg = treecorr.GGCorrelation(min_sep=1., max_sep=200., nbins=20, num_threads=1, sep_units='arcmin')\n",
    "\n",
    "    if dataframe1 is dataframe2:   \n",
    "        #print(pixel1, pixel2, \"same!\")\n",
    "        cat1 = treecorr.Catalog(ra=dataframe1.ra, dec=dataframe1.dec, g1=dataframe1.g1, g2=dataframe1.g2, flip_g2=False, ra_units='deg', dec_units='deg')\n",
    "        gg.process_auto(cat1)\n",
    "        \n",
    "        del cat1\n",
    "    else:\n",
    "        #print(pixel1, pixel2, \"different!\")\n",
    "        cat1 = treecorr.Catalog(ra=dataframe1.ra, dec=dataframe1.dec, g1=dataframe1.g1, g2=dataframe1.g2, flip_g2=False, ra_units='deg', dec_units='deg')\n",
    "        cat2 = treecorr.Catalog(ra=dataframe2.ra, dec=dataframe2.dec, g1=dataframe2.g1, g2=dataframe2.g2, flip_g2=False, ra_units='deg', dec_units='deg')\n",
    "        gg.process_cross(cat1, cat2)\n",
    "        \n",
    "        del cat1\n",
    "        del cat2\n",
    "             \n",
    "    del dataframe1 \n",
    "    del dataframe2\n",
    "    \n",
    "    return gg\n",
    "\n",
    "@delayed\n",
    "def size_test(dataframe1, dataframe2):\n",
    "    \n",
    "    gg = 1\n",
    "    \n",
    "    del dataframe1 \n",
    "    del dataframe2\n",
    "\n",
    "    return gg\n",
    "\n",
    "def calculateVariance(dataframe):\n",
    "    cat = treecorr.Catalog(ra=dataframe.ra, dec=dataframe.dec, g1=dataframe.g1, g2=dataframe.g2, flip_g2=False, ra_units='deg', dec_units='deg')\n",
    "    return pd.DataFrame([[cat.varg*cat.sumw, cat.sumw]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_list = list(df.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_list = df.to_delayed()\n",
    "partition_map = {j:i for i,j in enumerate(pixel_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = df.map_partitions(calculateVariance).sum().compute()\n",
    "varg = elements[0]/elements[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.array( [x for x in it.combinations_with_replacement(pixel_list, 2)] )\n",
    "selected_pairs = pairs[angular_distance(pairs) < 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a = [cross( delayed_list[partition_map[i[0]]], delayed_list[partition_map[i[1]]], i[0], i[1] ) for i in selected_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = [size_test(delayed_list[partition_map[i[0]]], delayed_list[partition_map[i[1]]]) for i in selected_pairs]\n",
    "#a = [size_test(delayed_list[partition_map[i[0]]], delayed_list[partition_map[i[1]]]) for i in selected_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gg_list = dask.compute(*a[10000:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gg = reduce(treecorr.GGCorrelation.__iadd__, gg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del gg_list\n",
    "client.cancel(gg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gg.finalize(varg, varg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(gg.meanr, gg.xip, yerr=np.sqrt(gg.varxip), marker='.', markersize=9, label=r'$\\xi_{+}$', ls='none')\n",
    "plt.errorbar(gg.meanr, gg.xim, yerr=np.sqrt(gg.varxim), marker='.', markersize=9, label=r'$\\xi_{-}$', ls='none')\n",
    "\n",
    "plt.title('$\\gamma \\gamma$ Correlation')\n",
    "plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.ylabel(r'$\\xi$')\n",
    "plt.xlabel(r'$\\theta$ (arcmin)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "\n",
    "def trim_memory() -> int:\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)\n",
    "\n",
    "client.run(trim_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask",
   "language": "python",
   "name": "dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
